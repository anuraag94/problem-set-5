{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Regina Catipon\n",
    "MACS 30100\n",
    "2/29/2020\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.linear_model import LogisticRegression, ElasticNetCV, ElasticNet \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n",
    "\n",
    "#from sklearn.inspection import plot_partial_dependence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: blue\">Conceptual: Cost functions for classification trees\n",
    "\n",
    "<span style=\"color: blue\">1. (15 points) Consider the Gini index, classification error, and cross-entropy in simple classification settings with two classes. Of these three possible cost functions, which would be best to use when growing a decision tree? Which would be best to use when pruning a decision tree? Why?\n",
    "\n",
    "Because classification error is simply the fraction of misclassified training observations it is not sensitive enough for tree growing. The other two impurity measures, the Gini index and cross-entropy are considered to be best because they control for variance across the classes which helps to optimize splitting for growth. For pruning, classifcation error is considered to be an appropriate measure because it prioritizes accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application: Predicting attitudes towards racist college professors\n",
    "\n",
    "## Estimate the models\n",
    "2. (35 points; 5 points/model) Estimate the following models, predicting colrac using the training set (the training .csv) with 10-fold CV:\n",
    "    - Logistic regression\n",
    "    - Naive Bayes\n",
    "    - Elastic net regression\n",
    "    - Decision tree (CART)\n",
    "    - Bagging\n",
    "    - Random forest\n",
    "    - Boosting\n",
    "\n",
    "Tune the relevant hyperparameters for each model as necessary. Only use the tuned model with the best performance for the remaining exercises. Be sure to leave sufficient time for hyperparameter tuning. Grid searches can be computationally taxing and take quite a while, especially for tree-aggregation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "train = pd.read_csv(\"./data/gss_train.csv\")\n",
    "test = pd.read_csv(\"./data/gss_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                       0\n",
       "attend                    0\n",
       "authoritarianism          0\n",
       "black                     0\n",
       "born                      0\n",
       "childs                    0\n",
       "colath                    0\n",
       "colrac                    0\n",
       "colcom                    0\n",
       "colmil                    0\n",
       "colhomo                   0\n",
       "colmslm                   0\n",
       "con_govt                  0\n",
       "egalit_scale              0\n",
       "evangelical               0\n",
       "grass                     0\n",
       "happy                     0\n",
       "hispanic_2                0\n",
       "homosex                   0\n",
       "income06                  0\n",
       "mode                      0\n",
       "owngun                    0\n",
       "polviews                  0\n",
       "pornlaw2                  0\n",
       "pray                      0\n",
       "pres08                    0\n",
       "reborn_r                  0\n",
       "science_quiz              0\n",
       "sex                       0\n",
       "sibs                      0\n",
       "social_connect            0\n",
       "south                     0\n",
       "teensex                   0\n",
       "tolerance                 0\n",
       "tvhours                   0\n",
       "vetyears                  0\n",
       "wordsum                   0\n",
       "degree_Bachelor.deg       0\n",
       "degree_other              0\n",
       "marital_Divorced          0\n",
       "marital_Never.married     0\n",
       "marital_other             0\n",
       "news_FEW.TIMES.A.WEEK     0\n",
       "news_LESS.THAN.ONCE.WK    0\n",
       "news_NEVER                0\n",
       "news_other                0\n",
       "partyid_3_Ind             0\n",
       "partyid_3_Rep             0\n",
       "relig_CATHOLIC            0\n",
       "relig_NONE                0\n",
       "relig_other               0\n",
       "social_cons3_Mod          0\n",
       "social_cons3_Conserv      0\n",
       "spend3_Mod                0\n",
       "spend3_Liberal            0\n",
       "zodiac_other              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspect\n",
    "train.head()\n",
    "#don't have to check for nulls because of preprocessinh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping colrac column and set predictors\n",
    "X_train = train.drop(['colrac'], axis=1)\n",
    "X_test = test.drop(['colrac'], axis=1)\n",
    "\n",
    "#setting prediction output to colrac\n",
    "y_train, y_test = train['colrac'], test['colrac']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic regression\n",
    "\n",
    "log_reg = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC/ROC 0.8080500250922787\n",
      "Error 0.7344474902240962\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "#AUC\n",
    "nb_score = cross_val_score(naive_bayes, X_train, \n",
    "                           y_train, scoring = 'roc_auc', cv = 10)\n",
    "nb_roc = np.mean(nb_score)\n",
    "\n",
    "#\n",
    "nb_accu = cross_val_score(naive_bayes, X_train, \n",
    "                           y_train, scoring = 'accuracy', cv = 10)\n",
    "nb_err = np.mean(nb_accu)\n",
    "\n",
    "print(\"AUC/ROC\", nb_roc)\n",
    "print(\"Error\", nb_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0038452641680228584 0.5\n"
     ]
    }
   ],
   "source": [
    "#Elastic net regression\n",
    "\n",
    "elas = ElasticNetCV(cv=10)\n",
    "elas.fit(X_train, y_train)\n",
    "\n",
    "# have to tune alpha and l1\n",
    "print( elas.alpha_, elas.l1_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC/ROC 0.8740225489138439\n",
      "Error 0.1471453221731916\n"
     ]
    }
   ],
   "source": [
    "#using that alpha and l1 ratio\n",
    "elas_best = ElasticNet(alpha = 0.0038452641680228584, l1_ratio=0.5)\n",
    "\n",
    "# is MSE best?\n",
    "elas_score = cross_val_score(elas_best, X_train, y_train,\n",
    "                          scoring = 'neg_mean_squared_error', cv=10)\n",
    "elas_mse = np.mean(elas_score)\n",
    "\n",
    "#AUC/ROC\n",
    "elas_score = cross_val_score(elas_best, X_train, y_train,\n",
    "                          scoring = 'roc_auc', cv=10)\n",
    "elas_roc = np.mean(elas_roc)\n",
    "\n",
    "print(\"AUC/ROC\", elas_roc)\n",
    "print(\"Error\", -1*elas_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC/ROC 0.8080500250922787\n",
      "Accuracy 0.7344474902240962\n"
     ]
    }
   ],
   "source": [
    "#Decision tree (CART)\n",
    "#Bagging\n",
    "#Random forest\n",
    "\n",
    "#Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the models\n",
    "3. (20 points) Compare and present each model's (training) performance based on\n",
    "    - Cross-validated error rate\n",
    "    - ROC/AUC\n",
    "\n",
    "4. (15 points) Which is the best model? Defend your choice.\n",
    "\n",
    "## Evaluate the best model\n",
    "5. (15 points) Evaluate the final, best model's (selected in 4) performance on the test set (the test .csv) by calculating and presenting the classification error rate and AUC. Compared to the fit evaluated on the training set in questions 3-4, does the \"best\" model generalize well? Why or why not? How do you know?\n",
    "\n",
    "## Bonus: PDPs/ICE\n",
    "6. (Up to 5 extra points) Present and substantively interpret the \"best\" model (selected in question 4) using PDPs/ICE curves over the range of: tolerance and age. Note, interpretation must be more than simple presentation of plots/curves. You must sufficiently describe the changes in probability estimates over the range of these two features. You may earn up to 5 extra points, where partial credit is possible if the solution is insufficient along some dimension (e.g., technically/code, interpretation, visual presentation, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
