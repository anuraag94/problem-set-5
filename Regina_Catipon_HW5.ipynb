{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Regina Catipon\n",
    "MACS 30100\n",
    "2/29/2020\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.linear_model import LogisticRegression, ElasticNetCV, ElasticNet \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n",
    "\n",
    "#from sklearn.inspection import plot_partial_dependence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: blue\">Conceptual: Cost functions for classification trees\n",
    "\n",
    "<span style=\"color: blue\">1. (15 points) Consider the Gini index, classification error, and cross-entropy in simple classification settings with two classes. Of these three possible cost functions, which would be best to use when growing a decision tree? Which would be best to use when pruning a decision tree? Why?\n",
    "\n",
    "Because classification error is simply the fraction of misclassified training observations it is not sensitive enough for tree growing. The other two impurity measures, the Gini index and cross-entropy are considered to be best because they control for variance across the classes which helps to optimize splitting for growth. For pruning, classifcation error is considered to be an appropriate measure because it prioritizes accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: blue\">Application: Predicting attitudes towards racist college professors\n",
    "\n",
    "## <span style=\"color: blue\">Estimate the models\n",
    "<span style=\"color: blue\">2. (35 points; 5 points/model) Estimate the following models, predicting colrac using the training set (the training .csv) with 10-fold CV:\n",
    "    - Logistic regression\n",
    "    - Naive Bayes\n",
    "    - Elastic net regression\n",
    "    - Decision tree (CART)\n",
    "    - Bagging\n",
    "    - Random forest\n",
    "    - Boosting\n",
    "\n",
    "<span style=\"color: blue\">Tune the relevant hyperparameters for each model as necessary. Only use the tuned model with the best performance for the remaining exercises. Be sure to leave sufficient time for hyperparameter tuning. Grid searches can be computationally taxing and take quite a while, especially for tree-aggregation methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "train = pd.read_csv(\"./data/gss_train.csv\")\n",
    "test = pd.read_csv(\"./data/gss_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>attend</th>\n",
       "      <th>authoritarianism</th>\n",
       "      <th>black</th>\n",
       "      <th>born</th>\n",
       "      <th>childs</th>\n",
       "      <th>colath</th>\n",
       "      <th>colrac</th>\n",
       "      <th>colcom</th>\n",
       "      <th>colmil</th>\n",
       "      <th>...</th>\n",
       "      <th>partyid_3_Ind</th>\n",
       "      <th>partyid_3_Rep</th>\n",
       "      <th>relig_CATHOLIC</th>\n",
       "      <th>relig_NONE</th>\n",
       "      <th>relig_other</th>\n",
       "      <th>social_cons3_Mod</th>\n",
       "      <th>social_cons3_Conserv</th>\n",
       "      <th>spend3_Mod</th>\n",
       "      <th>spend3_Liberal</th>\n",
       "      <th>zodiac_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  attend  authoritarianism  black  born  childs  colath  colrac  colcom  \\\n",
       "0   21       0                 4      0     0       0       1       1       0   \n",
       "1   42       0                 4      0     0       2       0       1       1   \n",
       "2   70       1                 1      1     0       3       0       1       1   \n",
       "3   35       3                 2      0     0       2       0       1       0   \n",
       "4   24       3                 6      0     1       3       1       1       0   \n",
       "\n",
       "   colmil  ...  partyid_3_Ind  partyid_3_Rep  relig_CATHOLIC  relig_NONE  \\\n",
       "0       1  ...              1              0               1           0   \n",
       "1       0  ...              1              0               0           0   \n",
       "2       0  ...              0              0               0           0   \n",
       "3       1  ...              1              0               0           0   \n",
       "4       0  ...              1              0               1           0   \n",
       "\n",
       "   relig_other  social_cons3_Mod  social_cons3_Conserv  spend3_Mod  \\\n",
       "0            0                 1                     0           0   \n",
       "1            0                 0                     0           1   \n",
       "2            0                 0                     0           0   \n",
       "3            1                 0                     0           0   \n",
       "4            0                 1                     0           0   \n",
       "\n",
       "   spend3_Liberal  zodiac_other  \n",
       "0               0             1  \n",
       "1               0             1  \n",
       "2               0             1  \n",
       "3               1             1  \n",
       "4               0             1  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inspect\n",
    "train.head()\n",
    "#don't have to check for nulls because of preprocessinh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping colrac column and set predictors\n",
    "X_train = train.drop(['colrac'], axis=1)\n",
    "X_test = test.drop(['colrac'], axis=1)\n",
    "\n",
    "#setting prediction output to colrac\n",
    "y_train, y_test = train['colrac'], test['colrac']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: blue\"> Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reginacatipon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/reginacatipon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/reginacatipon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/reginacatipon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/reginacatipon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/reginacatipon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/reginacatipon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/reginacatipon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/reginacatipon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/reginacatipon/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC/ROC 0.8703107556427476\n",
      "Error 0.7344474902240962\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "log_score = cross_val_score(log_reg, X_train, \n",
    "                           y_train, scoring = 'roc_auc', cv = 10)\n",
    "log_roc = np.mean(log_score)\n",
    "\n",
    "\n",
    "log_accu = cross_val_score(naive_bayes, X_train, \n",
    "                           y_train, scoring = 'accuracy', cv = 10)\n",
    "log_err = np.mean(log_accu)\n",
    "\n",
    "print(\"AUC/ROC\", log_roc)\n",
    "print(\"Error\", log_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color: blue\">Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC/ROC 0.8080500250922787\n",
      "Accuracy 0.7344474902240962\n"
     ]
    }
   ],
   "source": [
    "\n",
    "naive_bayes = GaussianNB()\n",
    "\n",
    "#AUC\n",
    "nb_score = cross_val_score(naive_bayes, X_train, \n",
    "                           y_train, scoring = 'roc_auc', cv = 10)\n",
    "nb_roc = np.mean(nb_score)\n",
    "\n",
    "#\n",
    "nb_accu = cross_val_score(naive_bayes, X_train, \n",
    "                           y_train, scoring = 'accuracy', cv = 10)\n",
    "nb_err = np.mean(nb_accu)\n",
    "\n",
    "print(\"AUC/ROC\", nb_roc)\n",
    "print(\"Accuracy\", nb_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color: blue\"> Elasticnet Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0038452641680228584 0.5\n"
     ]
    }
   ],
   "source": [
    "#Elastic net regression\n",
    "\n",
    "elas = ElasticNetCV(cv=10)\n",
    "elas.fit(X_train, y_train)\n",
    "\n",
    "# have to tune alpha and l1\n",
    "print( elas.alpha_, elas.l1_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC/ROC 0.8740225489138439\n",
      "MSE 0.1471453221731916\n"
     ]
    }
   ],
   "source": [
    "#using that alpha and l1 ratio\n",
    "elas_best = ElasticNet(alpha = 0.0038452641680228584, l1_ratio=0.5)\n",
    "\n",
    "# is MSE best?\n",
    "elas_score = cross_val_score(elas_best, X_train, y_train,\n",
    "                          scoring = 'neg_mean_squared_error', cv=10)\n",
    "elas_mse = np.mean(elas_score)\n",
    "\n",
    "#AUC/ROC\n",
    "elas_score = cross_val_score(elas_best, X_train, y_train,\n",
    "                          scoring = 'roc_auc', cv=10)\n",
    "elas_roc = np.mean(elas_roc)\n",
    "\n",
    "print(\"AUC/ROC\", elas_roc)\n",
    "print(\"MSE\", -1*elas_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color: blue\"> Decison Tree (CART)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC/ROC 0.7217232298218214\n",
      "Accuracy 0.7174588881444107\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "\n",
    "#AUC/ROC\n",
    "dt_score = cross_val_score(decision_tree, X_train, y_train,\n",
    "                          scoring = 'roc_auc', cv=10)\n",
    "dt_roc = np.mean(dt_score)\n",
    "\n",
    "#Error\n",
    "dt_accu = cross_val_score(decision_tree, X_train, y_train,\n",
    "                          scoring = 'accuracy', cv=10)\n",
    "dt_err = np.mean(dt_accu)\n",
    "\n",
    "#roc a bye baby\n",
    "print(\"AUC/ROC\", dt_roc)\n",
    "print(\"Accuracy\", dt_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color: blue\"> Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  93 out of 100 | elapsed:    9.4s remaining:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   10.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 30}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bagging, but what is the base?\n",
    "bagging = BaggingClassifier()\n",
    "\n",
    "param_grid = {'n_estimators': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50]}\n",
    "\n",
    "#Gridsearch?\n",
    "search = GridSearchCV(estimator = bagging, param_grid = param_grid,\n",
    "                      cv = 10, n_jobs=-1, verbose = 2)\n",
    "search.fit(X_train, y_train)\n",
    "search.best_params_\n",
    "\n",
    "#results = model_selection.cross_val_score(bagging, X_train, y_train, cv = search)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking those number of estimators\n",
    "bagging_best = BaggingClassifier(n_estimators=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC/ROC 0.8705380367452802\n",
      "Accuracy 0.7818464643248919\n"
     ]
    }
   ],
   "source": [
    "#AUC/ROC\n",
    "bag_score = cross_val_score(bagging_best, X_train, y_train,\n",
    "                          scoring = 'roc_auc', cv=10)\n",
    "bag_roc = np.mean(bag_score)\n",
    "\n",
    "#Error\n",
    "bag_accu = cross_val_score(bagging_best, X_train, y_train,\n",
    "                          scoring = 'accuracy', cv=10)\n",
    "bag_err = np.mean(bag_accu)\n",
    "\n",
    "#roc a bye baby\n",
    "print(\"AUC/ROC\", bag_roc)\n",
    "print(\"Accuracy\", bag_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color: blue\"> Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done 270 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done 676 tasks      | elapsed:   32.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:   52.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1972 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2862 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 3916 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4000 out of 4000 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 8, 'max_features': 25, 'n_estimators': 35}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "param_grid = {'n_estimators': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50], \n",
    "              'max_features':[5, 10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
    "              'max_depth': [2, 4, 6, 8],\n",
    "             }\n",
    "\n",
    "#GridSearch\n",
    "search_randf = GridSearchCV(estimator = random_forest, param_grid = param_grid,\n",
    "                      cv = 10, n_jobs=-1, verbose = 2)\n",
    "search_randf.fit(X_train, y_train)\n",
    "search_randf.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC/ROC 0.8798170843241266\n",
      "Accuracy 0.7750302007253109\n"
     ]
    }
   ],
   "source": [
    "random_forest_best = RandomForestClassifier(max_depth= 8, max_features= 25, n_estimators=35)\n",
    "\n",
    "#AUC/ROC\n",
    "rf_score = cross_val_score(random_forest_best, X_train, y_train,\n",
    "                          scoring = 'roc_auc', cv=10)\n",
    "rf_roc = np.mean(rf_score)\n",
    "\n",
    "#Error\n",
    "rf_accu = cross_val_score(bagging_best, X_train, y_train,\n",
    "                          scoring = 'accuracy', cv=10)\n",
    "rf_err = np.mean(rf_accu)\n",
    "\n",
    "#roc a bye baby\n",
    "print(\"AUC/ROC\", rf_roc)\n",
    "print(\"Accuracy\", rf_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1476, 55)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color: blue\"> Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 125 candidates, totalling 1250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 245 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=-1)]: Done 651 tasks      | elapsed:   36.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1217 tasks      | elapsed:   55.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1243 out of 1250 | elapsed:   56.5s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1250 out of 1250 | elapsed:   56.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.2, 'max_features': 30, 'n_estimators': 40}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "gradient = GradientBoostingClassifier()\n",
    "\n",
    "param_grid = { 'max_features': [10,20,30,40,50],\n",
    "              'learning_rate': [.2,.4,.6,.8,1],\n",
    "              'n_estimators': [10,20,30,40,50]\n",
    "             }\n",
    "\n",
    "    \n",
    "gradient_search = GridSearchCV(estimator =gradient, param_grid = param_grid,\n",
    "                              cv = 10, n_jobs = -1, verbose = 2)\n",
    "\n",
    "#fit the model\n",
    "gradient_search.fit(X_train,y_train)\n",
    "\n",
    "gradient_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_best = GradientBoostingClassifier(learning_rate = 0.2, \n",
    "                                           max_features = 30,\n",
    "                                          n_estimators = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reginacatipon/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/reginacatipon/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC/ROC 0.8689044470809119\n",
      "Accuracy 0.7845701510414426\n"
     ]
    }
   ],
   "source": [
    "#AUC/ROC\n",
    "gradient_score = cross_val_score(gradient_best, X_train, y_train,scoring = 'roc_auc')\n",
    "gradient_roc = np.mean(gradient_score)\n",
    "\n",
    "#Error\n",
    "gradient_accu = cross_val_score(gradient_best, X_train, y_train,scoring = 'accuracy')\n",
    "gradient_err = np.mean(gradient_accu)\n",
    "\n",
    "#roc a bye baby\n",
    "print(\"AUC/ROC\", gradient_roc)\n",
    "print(\"Accuracy\", gradient_err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color: blue\">Evaluate the models\n",
    "<span style=\"color: blue\">3. (20 points) Compare and present each model's (training) performance based on\n",
    "    - Cross-validated error rate \n",
    "    - ROC/AUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the models error rates\n",
    "\n",
    "#Plot model AUC/ROC\n",
    "\n",
    "#Plot recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <span style=\"color: blue\">4.(15 points) Which is the best model? Defend your choice.\n",
    "    \n",
    "The model that did the best was the Random Forest classifier. It scored an AUC/ROC rate of 0.879. While simpler models like Logistic Regression actually scored pretty close with 0.870, Random Forest also had one of the highest accuracy scores, second only to the Gradient Boosting in clssification error rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style=\"color: blue\">Evaluate the best model\n",
    " <span style=\"color: blue\">5. (15 points) Evaluate the final, best model's (selected in 4) performance on the test set (the test .csv) by calculating and presenting the classification error rate and AUC. Compared to the fit evaluated on the training set in questions 3-4, does the \"best\" model generalize well? Why or why not? How do you know?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_best.fit(X_train, y_train)\n",
    "pred = random_forest_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7971602434077079\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.788356504468719\n"
     ]
    }
   ],
   "source": [
    "#ROC/AUC\n",
    "roc = roc_auc_score(y_test, pred)\n",
    "print(roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think the model does an average job at generalizing. For example, the Naive Bayes classification, which is sometimes used as a baseline, had a ROC/AUC of 0.81 and an accuracy of 0.73. The ROC/AUC from the predicted y using the tuned Random Forest classification model was a little lower than the Naive Bayes rate at 0.79, and an accuracy score was a little higher than . It, of course, did not outperform the training results, but its accuracy was close to, if not sometimes better, than the training set fits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: PDPs/ICE\n",
    "6. (Up to 5 extra points) Present and substantively interpret the \"best\" model (selected in question 4) using PDPs/ICE curves over the range of: tolerance and age. Note, interpretation must be more than simple presentation of plots/curves. You must sufficiently describe the changes in probability estimates over the range of these two features. You may earn up to 5 extra points, where partial credit is possible if the solution is insufficient along some dimension (e.g., technically/code, interpretation, visual presentation, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
